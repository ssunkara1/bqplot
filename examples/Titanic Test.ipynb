{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./Data/Titanic/train.csv', header=0)\n",
    "# test_df = pd.read_csv('./Data/Titanic/test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll impute missing values using the median for numeric columns and the most\n",
    "# common value for string columns.\n",
    "\n",
    "# from sklearn.base import TransformerMixin\n",
    "# class DataFrameImputer(TransformerMixin):\n",
    "#     def fit(self, X, y=None):\n",
    "#         self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "#             if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "#             index=X.columns)\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X, y=None):\n",
    "#         return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns_to_use = ['Pclass', 'Sex', 'Age', 'Fare', 'Parch', 'SibSp']\n",
    "nonnumeric_columns = ['Sex']\n",
    "\n",
    "train_portion = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## randomizing the train and test data for the model\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
    "# test_df = test_df.reindex(np.random.permutation(test_df.index))\n",
    "\n",
    "data_size = train_df.shape[0]\n",
    "cutoff_idx = int(train_portion * data_size)\n",
    "\n",
    "final_train_df = train_df.iloc[:cutoff_idx, :]\n",
    "final_test_df = train_df.iloc[cutoff_idx:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medians = final_train_df.loc[:, feature_columns_to_use].median().to_dict()\n",
    "max_counts = {k: final_train_df.loc[:, k].value_counts().index[0] for k in nonnumeric_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in feature_columns_to_use:\n",
    "    null_vals = final_train_df.loc[:, col].isnull().values\n",
    "    if col in nonnumeric_columns:\n",
    "        final_train_df.loc[null_vals, col] = max_counts[col]\n",
    "    else:\n",
    "        final_train_df.loc[null_vals, col] = medians[col]\n",
    "        \n",
    "for col in feature_columns_to_use:\n",
    "    null_vals = final_test_df.loc[:, col].isnull().values\n",
    "    if col in nonnumeric_columns:\n",
    "        final_test_df.loc[null_vals, col] = max_counts[col]\n",
    "    else:\n",
    "        final_test_df.loc[null_vals, col] = medians[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for feature in nonnumeric_columns:\n",
    "    le.fit(train_df[feature])\n",
    "    final_train_df.loc[:, feature] = le.transform(final_train_df[feature])\n",
    "    final_test_df.loc[:, feature] = le.transform(final_test_df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_weights(train_series):\n",
    "    tr_counts_df = train_series.value_counts()\n",
    "    return (1. / (tr_counts_df / tr_counts_df.sum())).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the inputs for the model\n",
    "# train_X = big_X_imputed[0:train_df.shape[0]].as_matrix()\n",
    "# test_X = big_X_imputed[train_df.shape[0]:].as_matrix()\n",
    "# train_y = train_df['Survived']\n",
    "train_X = final_train_df.loc[:, feature_columns_to_use].values\n",
    "train_y = final_train_df.loc[:, 'Survived'].values.flatten()\n",
    "\n",
    "test_X = final_test_df.loc[:, feature_columns_to_use].values\n",
    "test_y_ref = final_test_df.loc[:, 'Survived'].values.flatten()\n",
    "\n",
    "tr_wght_func, test_wght_func = get_class_weights(final_train_df['Survived']), get_class_weights(final_test_df['Survived'])\n",
    "tr_weights = final_train_df['Survived'].map(tr_wght_func)\n",
    "test_weights = final_test_df['Survived'].map(test_wght_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xgb_imp(xgb, feat_names):\n",
    "    imp_vals = xgb.booster().get_fscore()\n",
    "    imp_dict = {feat_names[i]:float(imp_vals.get('f'+str(i),0.)) for i in range(len(feat_names))}\n",
    "    total = np.array(list(imp_dict.values())).sum()\n",
    "    return {k:v/total for k,v in imp_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.821229050279\n",
      "Train score is:  0.879213483146\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(max_depth=4, n_estimators=100, learning_rate=0.05).fit(train_X, train_y)\n",
    "pred_unweighted = gbm.predict(test_X)\n",
    "\n",
    "_imp_unweighted_ = get_xgb_imp(gbm, feature_columns_to_use)\n",
    "imp_unwghtd = [_imp_unweighted_[f] for f in feature_columns_to_use]\n",
    "\n",
    "print(\"Test score is: \", gbm.score(test_X, test_y_ref))\n",
    "print(\"Train score is: \", gbm.score(train_X, train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighting Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.801735559089\n",
      "Train score is:  0.837091290871\n"
     ]
    }
   ],
   "source": [
    "gbm_w = xgb.XGBClassifier(max_depth=4, n_estimators=100, learning_rate=0.01)\n",
    "gbm_w = gbm_w.fit(train_X, train_y, sample_weight=tr_weights)\n",
    "predictions = gbm_w.predict(test_X)\n",
    "\n",
    "_imp_weighted_ = get_xgb_imp(gbm_w, feature_columns_to_use)\n",
    "imp_wghtd = [_imp_weighted_[f] for f in feature_columns_to_use]\n",
    "\n",
    "print(\"Test score is: \", gbm_w.score(test_X, test_y_ref, sample_weight=test_weights))\n",
    "print(\"Train score is: \", gbm_w.score(train_X, train_y, sample_weight=tr_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget": "48b077f3263a4696a015b5c090afcfd6"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_imp = list(zip(*zip(imp_unwghtd, imp_wghtd)))\n",
    "\n",
    "from bqplot import pyplot as plt\n",
    "\n",
    "plt.figure(title='XGBoost Importances')\n",
    "plt.bar(feature_columns_to_use, xgb_imp, type='grouped', labels=['Unweighted', 'Weighted'],\n",
    "        display_legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.804469273743\n",
      "Train score is:  0.84691011236\n"
     ]
    }
   ],
   "source": [
    "grad_booster = GradientBoostingClassifier(max_depth=3, n_estimators=100, learning_rate=0.01)\n",
    "grad_booster.fit(train_X, train_y)\n",
    "\n",
    "gbt_prediction = grad_booster.predict(test_X)\n",
    "\n",
    "print(\"Test score is: \", grad_booster.score(test_X, test_y_ref))\n",
    "print(\"Train score is: \", grad_booster.score(train_X, train_y))\n",
    "\n",
    "gbt_imp_unwghtd = grad_booster.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget": "c0e97c70b8bc4b48b51ea80ce5651bfe"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unwghtd_imps = list(zip(*(zip(imp_unwghtd, gbt_imp_unwghtd))))\n",
    "\n",
    "plt.figure(title='Unweighted Importances xgboost vs gbt')\n",
    "plt.bar(feature_columns_to_use, unwghtd_imps, type='grouped', labels=['xgboost', 'gbt'], display_legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighting Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.797231054584\n",
      "Train score is:  0.857614238576\n"
     ]
    }
   ],
   "source": [
    "grad_booster_wgt = GradientBoostingClassifier(max_depth=3, n_estimators=500, learning_rate=0.01)\n",
    "\n",
    "counts_df = final_train_df['Survived'].value_counts()\n",
    "counts_dict = (1. / (counts_df / counts_df.sum())).to_dict()\n",
    "train_weights = final_train_df['Survived'].map(counts_dict)\n",
    "\n",
    "grad_booster_wgt.fit(train_X, train_y, sample_weight=tr_weights)\n",
    "gbt_prediction = grad_booster_wgt.predict(test_X)\n",
    "\n",
    "print(\"Test score is: \", grad_booster_wgt.score(test_X, test_y_ref, sample_weight=test_weights))\n",
    "print(\"Train score is: \", grad_booster_wgt.score(train_X, train_y, sample_weight=tr_weights))\n",
    "\n",
    "gbt_imp_wghtd = grad_booster_wgt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget": "a74feaa1ab104ca1bff22aec13414163"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wghtd_imps = list(zip(*(zip(imp_wghtd, gbt_imp_wghtd))))\n",
    "\n",
    "plt.figure(title='Class Weighted Importances xgboost vs gbt')\n",
    "plt.bar(feature_columns_to_use, wghtd_imps, type='grouped', labels=['xgboost', 'gbt'], display_legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with XGBoost -- Unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.877808988764\n",
      "Test score:  0.826815642458\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(n_estimators=100)\n",
    "\n",
    "xgb_params_dict = {'learning_rate': [0.001, 0.01, 0.1],\n",
    "                   'max_depth': [3, 4, 5],\n",
    "                   'subsample': [0.75, 0.9, 1.0]}\n",
    "\n",
    "clf = GridSearchCV(xgb_classifier, xgb_params_dict, n_jobs=-1, cv=5)\n",
    "## assigning to supress output\n",
    "_ = clf.fit(train_X, train_y)\n",
    "\n",
    "xgb_classifier.set_params(**clf.best_params_)\n",
    "xgb_classifier.fit(train_X, train_y)\n",
    "\n",
    "print('Train score: ', xgb_classifier.score(train_X, train_y))\n",
    "print('Test score: ', xgb_classifier.score(test_X, test_y_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with XGBoost -- Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.856705996067\n",
      "Test score:  0.785373608903\n"
     ]
    }
   ],
   "source": [
    "xgb_cl_wghtd = xgb.XGBClassifier(n_estimators=100)\n",
    "\n",
    "xgb_params_dict = {'learning_rate': [0.001, 0.01, 0.1],\n",
    "                   'max_depth': [3, 4, 5],\n",
    "                   'subsample': [0.75, 0.9, 1.0]}\n",
    "\n",
    "clf = GridSearchCV(xgb_cl_wghtd, xgb_params_dict, n_jobs=-1, cv=5, fit_params={'sample_weight': tr_weights})\n",
    "## assigning to supress output\n",
    "_ = clf.fit(train_X, train_y)\n",
    "\n",
    "xgb_cl_wghtd.set_params(**clf.best_params_)\n",
    "xgb_cl_wghtd.fit(train_X, train_y, sample_weight=tr_weights)\n",
    "\n",
    "print('Train score: ', xgb_cl_wghtd.score(train_X, train_y, sample_weight=tr_weights))\n",
    "print('Test score: ', xgb_cl_wghtd.score(test_X, test_y_ref, sample_weight=test_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.804469273743\n",
      "Train score is:  0.845505617978\n"
     ]
    }
   ],
   "source": [
    "rf_clas = RandomForestClassifier(max_depth=3, n_estimators=100, max_features='auto')\n",
    "rf_clas.fit(train_X, train_y)\n",
    "\n",
    "rf_pred = rf_clas.predict(test_X)\n",
    "\n",
    "print(\"Test score is: \", rf_clas.score(test_X, test_y_ref))\n",
    "print(\"Train score is: \", rf_clas.score(train_X, train_y))\n",
    "\n",
    "rf_imp_unwghtd = rf_clas.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget": "a0e03505b1a74d348bbe764af05237ce"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unwghtd_imps = list(zip(*(zip(imp_unwghtd, rf_imp_unwghtd))))\n",
    "\n",
    "plt.figure(title='Unweighted Importances xgboost vs Random Forest')\n",
    "plt.bar(feature_columns_to_use, unwghtd_imps, type='grouped', labels=['xgboost', 'Random Forest'], display_legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.771131425543\n",
      "Train score is:  0.825917408259\n"
     ]
    }
   ],
   "source": [
    "rf_clas_wgt = RandomForestClassifier(max_depth=3, n_estimators=100, max_features='auto')\n",
    "rf_clas_wgt.fit(train_X, train_y, sample_weight=tr_weights.values)\n",
    "\n",
    "rf_pred = rf_clas.predict(test_X)\n",
    "\n",
    "print(\"Test score is: \", rf_clas.score(test_X, test_y_ref, sample_weight=test_weights))\n",
    "print(\"Train score is: \", rf_clas.score(train_X, train_y, sample_weight=tr_weights))\n",
    "\n",
    "rf_imp_unwghtd = rf_clas.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "widgets": {
   "state": {
    "48b077f3263a4696a015b5c090afcfd6": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "a0e03505b1a74d348bbe764af05237ce": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "a74feaa1ab104ca1bff22aec13414163": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "c0e97c70b8bc4b48b51ea80ce5651bfe": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "2.0.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
