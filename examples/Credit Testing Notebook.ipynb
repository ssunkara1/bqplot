{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 30 18:37:16 2017\n",
    "\n",
    "@author: ssunkara1\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import time\n",
    "start_time = time.clock()\n",
    "\n",
    "#%%\n",
    "try:\n",
    "    _ = seed\n",
    "except NameError:\n",
    "    seed = None\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "data_root = 'C:/Users/ssunkara1/AppData/Local/bipy/12007280/notebooks/My Notebooks/team_notebooks/'\n",
    "data_df_total = pd.read_csv(data_root + 'Data/Credit Data/cs-training.csv', index_col=0)\n",
    "result_column = 'SeriousDlqin2yrs'\n",
    "\n",
    "train_idx, test_idx = train_test_split(data_df_total.index.values, test_size=0.3,\n",
    "                                       stratify=data_df_total[result_column]\n",
    "                                       )\n",
    "strat_cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "train_data = data_df_total.loc[train_idx]\n",
    "test_data = data_df_total.loc[test_idx]\n",
    "\n",
    "try:\n",
    "    _ = reset_seed\n",
    "except NameError:\n",
    "    reset_seed = False\n",
    "\n",
    "if reset_seed:\n",
    "    np.random.seed(None)   \n",
    "\n",
    "#%%\n",
    "impute_income = True\n",
    "stack_models = True\n",
    "fill_smart = True\n",
    "fit_expanded = False\n",
    "group_models = False\n",
    "rescale_models = False\n",
    "plot_figure = True\n",
    "\n",
    "# %%\n",
    "overdue_cols = ['NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfTimes90DaysLate']\n",
    "rev_lines_col = 'RevolvingUtilizationOfUnsecuredLines'\n",
    "\n",
    "def clean_data_for_prediction(data_frame):\n",
    "    # remove all nan monthly incomes\n",
    "    # remove NumberOfDaysLate >= 90.\n",
    "    # remove Revolving Utilization of Credit Lines >= 4.\n",
    "    # remove obscene values of DebtRatio.\n",
    "    # income greater than 1.\n",
    "    reduced_df = data_frame.copy()\n",
    "    reduced_df = reduced_df[~reduced_df['MonthlyIncome'].isnull()]\n",
    "    reduced_df = reduced_df[reduced_df['MonthlyIncome'] > 100.]\n",
    "    \n",
    "    for c in overdue_cols:\n",
    "        reduced_df = reduced_df[reduced_df[c] <= 90.]\n",
    "    \n",
    "    reduced_df = reduced_df[reduced_df[rev_lines_col] <= 4.]\n",
    "    return reduced_df\n",
    "\n",
    "def train_income_model(data_frame):\n",
    "    col_train_data = clean_data_for_prediction(data_frame)\n",
    "    col_train_X, col_train_y = col_train_data.drop(['MonthlyIncome', 'DebtRatio', result_column], axis=1), col_train_data['MonthlyIncome']\n",
    "    col_train_X = col_train_X.fillna(data_median)\n",
    "    \n",
    "    col_model = GradientBoostingRegressor(n_estimators=300, max_depth=7, max_features=4, \n",
    "                                          learning_rate=0.1,\n",
    "                                          min_weight_fraction_leaf=0.0001)\n",
    "    col_model.fit(col_train_X, col_train_y)\n",
    "    return col_model\n",
    "\n",
    "#%%:\n",
    "def clean_train_data(train_df):\n",
    "    train_df = train_df.copy()\n",
    "    \n",
    "    data_median = train_df.median()\n",
    "    nan_income = train_df.index[np.logical_or(train_df['MonthlyIncome'].isnull(), train_df['MonthlyIncome'] < 100.)]\n",
    "\n",
    "    if impute_income:\n",
    "        test_income_data = train_df.loc[nan_income].drop(['MonthlyIncome', 'DebtRatio', result_column], axis=1)\n",
    "        test_income_data = test_income_data.fillna(data_median)\n",
    "        income_fill_values = income_model.predict(test_income_data)\n",
    "    \n",
    "        train_df.loc[nan_income, 'MonthlyIncome'] = income_fill_values\n",
    "        train_df.loc[nan_income, 'DebtRatio'] = train_df.loc[nan_income, 'DebtRatio'] / income_fill_values       \n",
    "    else:\n",
    "        train_df.loc[nan_income, 'MonthlyIncome'] = data_median['MonthlyIncome']\n",
    "        train_df.loc[nan_income, 'DebtRatio'] = train_df.loc[nan_income, 'DebtRatio'] / data_median['MonthlyIncome']\n",
    "\n",
    "    fill_values = {}\n",
    "    fill_values['MonthlyIncome'] = data_median['MonthlyIncome']\n",
    "    \n",
    "    for col in overdue_cols:\n",
    "        num_overdue_df = train_df.loc[train_df[col] >= 90]\n",
    "        if fill_smart:\n",
    "            over_due_fill_values = train_df.loc[~train_df.index.isin(num_overdue_df.index)].groupby(result_column).mean()\n",
    "            fill_values[col] = over_due_fill_values[col].mean()\n",
    "            train_df.loc[num_overdue_df.index, col] = train_df.loc[num_overdue_df.index, result_column].map(lambda x: over_due_fill_values.loc[x, col])\n",
    "        else:                \n",
    "            fill_values[col] = train_df[col].median()\n",
    "            train_df.loc[num_overdue_df.index, col] = train_df[col].median()\n",
    " \n",
    "    ## filling the value for revolving unsecured lines.\n",
    "    rev_filtered_df = train_df[train_df[rev_lines_col] >= 4.0]\n",
    "    if fill_smart:\n",
    "        rev_fill_values = train_df.loc[~train_df.index.isin(rev_filtered_df.index)].groupby(result_column).median()\n",
    "        fill_values[rev_lines_col] = rev_fill_values[rev_lines_col].mean()\n",
    "        train_df.loc[rev_filtered_df.index, rev_lines_col] = train_df.loc[rev_filtered_df.index, result_column].map(lambda x: rev_fill_values.loc[x, rev_lines_col])\n",
    "    else:    \n",
    "        train_df.loc[rev_filtered_df.index, rev_lines_col] = train_df[rev_lines_col].median()\n",
    "        fill_values[rev_lines_col] = train_df[rev_lines_col].median()\n",
    "    return train_df, fill_values \n",
    "\n",
    "\n",
    "def clean_test_data(test_df, fill_values, fill_values_other):\n",
    "    test_df = test_df.copy()\n",
    "    nan_income_idxs = test_df.index[np.logical_or(test_df['MonthlyIncome'].isnull(), test_df['MonthlyIncome'] < 100.)]\n",
    "    \n",
    "    if impute_income:\n",
    "        test_income_data = test_df.loc[nan_income_idxs].drop(['MonthlyIncome', 'DebtRatio', result_column], axis=1)\n",
    "        test_income_data = test_income_data.fillna(fill_values_other)\n",
    "        income_fill_values = income_model.predict(test_income_data)   \n",
    "        test_df.loc[nan_income_idxs, 'MonthlyIncome'] = income_fill_values\n",
    "        test_df.loc[nan_income_idxs, 'DebtRatio'] = test_df.loc[nan_income_idxs, 'DebtRatio'] / income_fill_values               \n",
    "    else:\n",
    "        test_df.loc[nan_income_idxs, 'MonthlyIncome'] = fill_values['MonthlyIncome']\n",
    "        test_df.loc[nan_income_idxs, 'DebtRatio'] = test_df.loc[nan_income_idxs, 'DebtRatio'] / fill_values['MonthlyIncome']\n",
    "\n",
    "    for c in overdue_cols:\n",
    "        fill_idxs = test_df.index[test_df[c] >= 90]\n",
    "        test_df.loc[fill_idxs, c] = fill_values[c]\n",
    "\n",
    "    fill_rev_idxs = test_df.index[test_df[rev_lines_col] >= 4.0]\n",
    "    test_df.loc[fill_rev_idxs, rev_lines_col] = fill_values[rev_lines_col]\n",
    "\n",
    "    test_df = test_df.fillna(fill_values_other)\n",
    "    return test_df\n",
    "\n",
    "def add_features(data_frame):\n",
    "    return_dataframe = data_frame.copy()\n",
    "    return_dataframe[rev_lines_col+'ind'] = return_dataframe[rev_lines_col] == 0.\n",
    "    return_dataframe['overdue_ind'] = (return_dataframe[overdue_cols].sum(axis=1) == 0)\n",
    "    return return_dataframe\n",
    "\n",
    "#%%\n",
    "data_median = train_data.median()\n",
    "if impute_income:\n",
    "    income_model = train_income_model(train_data)\n",
    "\n",
    "train_data_clean, fill_dict = clean_train_data(train_data)\n",
    "data_median = train_data_clean.median()\n",
    "\n",
    "## fill in the remaining values with the median\n",
    "train_data_clean = train_data_clean.fillna(data_median)\n",
    "train_data_clean = add_features(train_data_clean)\n",
    "\n",
    "test_data_cleaned = clean_test_data(test_data, fill_dict, data_median)\n",
    "test_data_cleaned = add_features(test_data_cleaned)\n",
    "\n",
    "X_train = train_data_clean.drop(result_column, axis=1)\n",
    "y_train = train_data_clean[result_column]\n",
    "\n",
    "X_test = test_data_cleaned.drop(result_column, axis=1)\n",
    "y_test = test_data_cleaned[result_column]\n",
    "\n",
    "#%%\n",
    "## common utility functions\n",
    "def average_model_preds(*probs):\n",
    "    avg_probs = np.mean(probs, axis=0)\n",
    "    avg_preds = avg_probs > 0.5\n",
    "    return (avg_probs, avg_preds)\n",
    "\n",
    "def get_model_preds(model, predictors):\n",
    "    # get the probabilities and predictions for the model\n",
    "    return (model.predict_proba(predictors)[:, 1], model.predict(predictors))\n",
    "\n",
    "def get_total_model_preds(model, train_predictors, test_predictors):\n",
    "    train_probs, train_preds = get_model_preds(model, train_predictors)\n",
    "    test_probs, test_preds = get_model_preds(model, test_predictors)\n",
    "    \n",
    "    return ((train_probs, train_preds), (test_probs, test_preds))\n",
    "\n",
    "def eval_preds(y_true, y_probs, y_preds):\n",
    "    return {'precision': precision_score(y_true, y_preds),\n",
    "            'accuracy': accuracy_score(y_true, y_preds),\n",
    "            'recall': recall_score(y_true, y_preds),\n",
    "            'auc': roc_auc_score(y_true, y_probs)}\n",
    "\n",
    "def get_model_eval(true_train, train_predictions, true_test=None, test_predictions=None):\n",
    "    train_eval = eval_preds(true_train, *train_predictions)\n",
    "    if true_test is None:\n",
    "        return pd.Series(train_eval)\n",
    "    else:\n",
    "        test_eval = eval_preds(true_test, *test_predictions)\n",
    "        return pd.DataFrame([train_eval, test_eval], index=['Train', 'Test'])\n",
    "    \n",
    "def get_sample_weights(y_train, power=1.0):\n",
    "    y_train = pd.Series(y_train)\n",
    "    return y_train.map(1. - (y_train.value_counts() / len(y_train))) ** power    \n",
    "\n",
    "def probas_to_classes(probas):\n",
    "    return (probas >= 0.5).astype(float)\n",
    "\n",
    "#%%\n",
    "from keras.models import Sequential\n",
    "# from keras.utils.np_utils import probas_to_classes\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "class LossCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, *args):\n",
    "        self.train_auc = []\n",
    "        self.test_auc = []\n",
    "    \n",
    "    def on_epoch_end(self, *args):\n",
    "        train_probs = self.model.predict(X_train_norm)\n",
    "        test_probs = self.model.predict(X_test_norm)\n",
    "        self.train_auc.append(roc_auc_score(y_train.values.flatten(), train_probs))\n",
    "        self.test_auc.append(roc_auc_score(y_test.values.flatten(), test_probs))\n",
    "\n",
    "test_call_back = LossCallback()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_norm = scaler.fit_transform(X_train.values)\n",
    "X_test_norm = scaler.transform(X_test.values)\n",
    "reg_param = 0.\n",
    "reg_param_2 = 0.\n",
    "\n",
    "first_reg = regularizers.l2(reg_param)\n",
    "second_reg = regularizers.l2(reg_param_2)\n",
    "\n",
    "dropout_prob = 0.2\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=X_train_norm.shape[1], activation='relu',\n",
    "                W_regularizer=regularizers.l2(reg_param)))\n",
    "\n",
    "model.add(Dense(100, activation='relu',\n",
    "                W_regularizer=regularizers.l2(reg_param_2)))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=X_train_norm.shape[1], activation='relu',\n",
    "                W_regularizer=first_reg))\n",
    "model.add(Dropout(dropout_prob))\n",
    "\n",
    "#model.add(Dense(80, activation='relu', W_regularizer=first_reg))\n",
    "#model.add(Dropout(dropout_prob))\n",
    "#model.add(Dense(60, activation='relu', W_regularizer=first_reg))\n",
    "#model.add(Dropout(dropout_prob))\n",
    "#\n",
    "#model.add(Dense(30, activation='relu', W_regularizer=second_reg))\n",
    "model.add(Dense(10, activation='relu', W_regularizer=second_reg))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train_norm, y_train.values, verbose=0,\n",
    "          nb_epoch=50, batch_size=5000,\n",
    "           callbacks=[test_call_back])\n",
    "\n",
    "train_probs = model.predict(X_train_norm).flatten()\n",
    "train_preds = probas_to_classes(train_probs)\n",
    "\n",
    "test_probs = model.predict(X_test_norm).flatten()\n",
    "test_preds = probas_to_classes(test_probs)\n",
    "\n",
    "model_eval = get_model_eval(y_train, [train_probs, train_preds],\n",
    "                            y_test, [test_probs, test_preds])\n",
    "print(model_eval)\n",
    "train_auc = model_eval.loc['Train', 'auc']\n",
    "test_auc = model_eval.loc['Test', 'auc']\n",
    "\n",
    "if plot_figure:\n",
    "    plt.figure()\n",
    "    plt.plot(test_call_back.train_auc)\n",
    "    plt.plot(test_call_back.test_auc)\n",
    "    plt.show()\n",
    "\n",
    "#%%\n",
    "end_time = time.clock()\n",
    "print('Time Taken:', end_time - start_time)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
